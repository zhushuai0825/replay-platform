# 11. Celery 与 Redis 配置（详细步骤）

1. **安装/启动 Redis**
   - 使用 docker compose：`docker compose up -d redis`
   - 或本地运行 `redis-server`，确保地址与 `.env` 中一致
2. **配置 `.env`**
   ```
   CELERY_BROKER_URL=redis://redis:6379/0
   CELERY_RESULT_BACKEND=redis://redis:6379/1
   ```
   - `settings.py` 还导出了模块级变量 `CELERY_BROKER_URL` / `celery_broker_url`（同理 result_backend），确保 `celery -A app.celery_app worker` 能正确读取
3. **`app/celery_app.py`（已创建）**
   ```python
   from celery import Celery
   from app.config.settings import settings

   celery_app = Celery(
       "replay_platform",
       broker=settings.CELERY_BROKER_URL,
       backend=settings.CELERY_RESULT_BACKEND,
       include=["app.services.replay_engine"],
   )

   celery_app.conf.update(
       task_serializer="json",
       result_serializer="json",
       accept_content=["json"],
       timezone="Asia/Shanghai",
       enable_utc=True,
       task_track_started=True,
   )
   ```
4. **示例任务 `app/services/replay_engine.py`**
   ```python
   import time
   from datetime import datetime

   from app.celery_app import celery_app
   from app.databases import SessionLocal
   from app.models import ReplayTask
   from app.utils.logger import logger


   @celery_app.task(name="app.services.replay_engine.run_replay_task")
   def run_replay_task(task_id: int) -> str:
       db = SessionLocal()
       task = None
       try:
           task = db.query(ReplayTask).filter(ReplayTask.id == task_id).one_or_none()
           if not task:
               logger.warning("任务不存在: %s", task_id)
               return "task_not_found"

           task.status = "running"
           task.started_at = datetime.utcnow()
           task.total_requests = 5
           db.commit()

           for index in range(1, 6):
               time.sleep(1)
               task.completed_requests = index
               task.progress = int(index * 100 / task.total_requests)
               db.commit()

           task.status = "completed"
           task.completed_at = datetime.utcnow()
           db.commit()
           return "completed"
       except Exception:
           if task:
               task.status = "failed"
               db.commit()
           logger.exception("回放任务执行失败")
           raise
       finally:
           db.close()
   ```
5. **触发任务**
   ```python
   celery_app.send_task("app.services.replay_engine.run_replay_task", args=[task.id])
   ```
   - `app/api/tasks.py` 的 `create_task` 已包含上述逻辑，若发送失败会记录日志但不阻塞接口
6. **启动 Worker**
   ```bash
   cd backend
   celery -A app.celery_app.celery_app worker --loglevel=info
   ```
