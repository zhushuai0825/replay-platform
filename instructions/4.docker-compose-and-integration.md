# 4. Docker & 集成步骤

1. 在仓库根目录创建 `docker-compose.yml`
   ```yaml
   version: "3.9"
   services:
     postgres:
       image: postgres:15-alpine
       environment:
         POSTGRES_USER: replay_user
         POSTGRES_PASSWORD: replay_password
         POSTGRES_DB: replay_db
       volumes:
         - postgres_data:/var/lib/postgresql/data
       ports:
         - "5432:5432"
       healthcheck:
         test: ["CMD-SHELL", "pg_isready -U replay_user"]
         interval: 10s
         timeout: 5s
         retries: 5
     redis:
       image: redis:7-alpine
       ports:
         - "6379:6379"
       healthcheck:
         test: ["CMD", "redis-cli", "ping"]
         interval: 10s
         timeout: 5s
         retries: 5
     backend:
       build: ./backend
       env_file:
         - ./backend/.env
       depends_on:
         postgres:
           condition: service_healthy
         redis:
           condition: service_healthy
       ports:
         - "8000:8000"
     frontend:
       build: ./frontend
       ports:
         - "3000:80"
     celery-worker:
       build:
         context: ./backend
         dockerfile: celery.Dockerfile
       env_file:
         - ./backend/.env
       depends_on:
         redis:
           condition: service_healthy
   volumes:
     postgres_data:
   ```
2. backend `Dockerfile`
   1. 在 `backend/` 目录创建 `Dockerfile`，内容如下：
      ```Dockerfile
      FROM python:3.11-slim
      ENV PYTHONDONTWRITEBYTECODE=1 PYTHONUNBUFFERED=1
      WORKDIR /app

      COPY requirements.txt .
      RUN pip install --no-cache-dir -r requirements.txt

      COPY . .
      CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
      ```
   2. 可选：创建 `backend/.dockerignore`（忽略 venv、__pycache__ 等）。
3. Celery worker `celery.Dockerfile`
   ```Dockerfile
   FROM python:3.11-slim
   ENV PYTHONDONTWRITEBYTECODE=1 PYTHONUNBUFFERED=1
   WORKDIR /app

   COPY requirements.txt .
   RUN pip install --no-cache-dir -r requirements.txt

   COPY . .
   CMD ["celery", "-A", "app.celery_app.celery_app", "worker", "--loglevel=info"]
   ```
4. 前端 Dockerfile（生产构建 + Nginx 托管）
   ```Dockerfile
   FROM node:18-alpine AS build
   WORKDIR /app
   COPY package*.json ./
   RUN npm install
   COPY . .
   RUN npm run build

   FROM nginx:alpine
   COPY --from=build /app/dist /usr/share/nginx/html
   EXPOSE 80
   CMD ["nginx", "-g", "daemon off;"]
   ```

**重要说明：关于 PostgreSQL 和 Redis**

⚠️ **不需要单独下载或安装 PostgreSQL 和 Redis！**

- PostgreSQL 和 Redis 会通过 Docker Compose 自动启动为容器
- 用户名、密码、数据库名已在 `docker-compose.yml` 中配置好：
  - PostgreSQL: `replay_user` / `replay_password` / `replay_db`
  - Redis: 默认配置，无需密码
- `DATABASE_URL` 中的用户名和密码必须与 `docker-compose.yml` 中的配置保持一致
- 只需运行 `docker compose up -d`，Docker 会自动下载镜像并启动服务

**验证数据库是否运行：**
```bash
# 查看所有容器状态
docker compose ps

# 查看 PostgreSQL 日志
docker compose logs postgres

# 进入 PostgreSQL 容器测试连接
docker compose exec postgres psql -U replay_user -d replay_db
```

5. 启动与验证
   ```bash
   docker compose build
   docker compose up -d
   docker compose ps
   docker compose logs -f backend   # 查看后端日志
   ```
   浏览器访问：
   - http://localhost:3000 （前端）
   - http://localhost:8000/docs （后端 API 文档）
6. 常见问题与排查
   - 镜像下载慢：Docker Desktop → Settings → Docker Engine 配置 `registry-mirrors`
   - 服务未就绪：`docker compose logs -f [service]` 查看健康检查与错误
   - 数据持久化：确认 `postgres_data` 卷存在（`docker volume ls`），避免容器删除后数据丢失
